{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19288,"status":"ok","timestamp":1654192597892,"user":{"displayName":"miki998 Chan","userId":"13004190056137233486"},"user_tz":-120},"id":"8oqeLzwwWhWy","outputId":"77bd2504-52be-4121-e7c0-4640755c0c54"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount(\"/content/gdrive\")"],"id":"8oqeLzwwWhWy"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1653760510328,"user":{"displayName":"miki998 Chan","userId":"13004190056137233486"},"user_tz":-120},"id":"lWYQ5nj9WncU","outputId":"d1eb8344-672f-48ac-d680-ffcc81c8800f"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/LELSD/notebooks\n"]}],"source":["%cd ./gdrive/MyDrive/LELSD/notebooks/"],"id":"lWYQ5nj9WncU"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5BxVd12tZlqQ"},"outputs":[],"source":["# !pip install Ninja\n","# !python3.7 -m pip install torch==1.9.0\n","# !python3.7 -m pip install torchvision==0.10.0"],"id":"5BxVd12tZlqQ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"8f050d55-2b6d-40cc-b81b-3c550279086d"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import sys\n","\n","import torch\n","sys.path.append(\"../\")\n","import models\n","import torch\n","from utils.stylegan2_utils import StyleGAN2SampleGenerator\n","from utils.stylegan3_utils import StyleGAN3SampleGenerator\n","from utils.segmentation_utils import FaceSegmentation\n","from lelsd import LELSD"],"id":"8f050d55-2b6d-40cc-b81b-3c550279086d"},{"cell_type":"markdown","metadata":{"id":"760c75e9-8cdf-4274-837e-981469fc03b3"},"source":["# Training StyleGAN2 with Supervised Segmentation"],"id":"760c75e9-8cdf-4274-837e-981469fc03b3"},{"cell_type":"markdown","metadata":{"id":"233ed233-48da-4bd4-9003-fc18de04db40"},"source":["### StyleGAN2 FFHQ"],"id":"233ed233-48da-4bd4-9003-fc18de04db40"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0fedc90d-56a9-4f36-9c90-9150e5ccc1b8"},"outputs":[],"source":["device = torch.device('cuda')\n","\n","exp_dir = \"../out\"\n","G2 = models.get_model(\"stylegan2\", \"../pretrained/stylegan2/ffhq.pkl\")\n","stylegan2_sample_generator = StyleGAN2SampleGenerator(G=G2, device=device)\n","\n","face_bisenet = models.get_model(\"face_bisenet\", \"../pretrained/face_bisenet/model.pth\")\n","face_segmentation = FaceSegmentation(face_bisenet=face_bisenet, device=device)\n","\n","for latent_space in [\"S6\"]:\n","    for loss_function in [\"L2\"]:\n","        for mask_aggregation in [\n","            'average',\n","            'union',\n","            'intersection',\n","        ]:\n","\n","            for num_latent_dirs in [1, 2]:\n","                for part_name, face_parts in zip(\n","                        [\n","                            \"mouth\",\n","                            \"skin\",\n","                            \"eyes\",\n","                            \"nose\",\n","                            \"ears\",\n","                            \"background\",\n","                            \"eyebrows\",\n","                            \"hair\",\n","                            \"cloth\", \"eyeglass\"\n","\n","                        ],\n","                        [\n","                            [\"mouth\", \"u_lip\", \"l_lip\"],\n","                            [\"skin\"],\n","                            [\"l_eye\", \"r_eye\"],\n","                            [\"nose\"],\n","                            [\"l_ear\", \"r_ear\", \"earrings\"],\n","                            [\"background\"],\n","                            [\"l_brow\", \"r_brow\"],\n","                            [\"hair\", \"hat\"],\n","                            [\"hair\"],\n","                            [\"cloth\", \"neck\", \"necklace\"],\n","                            [\"eyeglass\"]\n","\n","                        ]\n","                ):\n","                    lr = 0.001\n","                    min_alpha_value = -1.0\n","                    max_alpha_value = 1.0\n","                    min_abs_alpha_value = 0.0\n","                    gamma_correlation = 5.0\n","                    onehot_temperature = 0.001\n","                    batch_size = 4\n","                    localization_layers = list(range(1, 18))\n","                    localization_layer_weights = None\n","                    log_dir = f'{exp_dir}/lelsd_stylegan2_ffhq/{latent_space}_{loss_function}_{mask_aggregation}/{num_latent_dirs}D/face_bisenet/{part_name}'\n","                    lelsd = LELSD(device=device,\n","                                  localization_layers=localization_layers,\n","                                  semantic_parts=face_parts,\n","                                  loss_function=loss_function,\n","                                  localization_layer_weights=localization_layer_weights,\n","                                  mode='foreground',\n","                                  mask_aggregation=mask_aggregation,\n","                                  n_layers=18,\n","                                  latent_dim=512,\n","                                  num_latent_dirs=num_latent_dirs,\n","                                  learning_rate=lr,\n","                                  batch_size=batch_size,\n","                                  gamma_correlation=gamma_correlation,\n","                                  unit_norm=False,\n","                                  latent_space=latent_space,\n","                                  onehot_temperature=onehot_temperature,\n","                                  min_alpha_value=min_alpha_value,\n","                                  max_alpha_value=max_alpha_value,\n","                                  min_abs_alpha_value=min_abs_alpha_value,\n","                                  log_dir=log_dir,\n","                                  )\n","\n","                    lelsd.fit(stylegan2_sample_generator, face_segmentation, num_batches=200 * num_latent_dirs,\n","                              num_lr_halvings=3,\n","                              pgbar=True, summary=True)\n","                    lelsd.save()"],"id":"0fedc90d-56a9-4f36-9c90-9150e5ccc1b8"},{"cell_type":"markdown","source":["# Training StyleGAN3 with Supervised Segmentation"],"metadata":{"id":"X1N4bTGaXgus"},"id":"X1N4bTGaXgus"},{"cell_type":"markdown","source":["### StyleGAN3-R FFHQ"],"metadata":{"id":"v8xhxQwiXj5f"},"id":"v8xhxQwiXj5f"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XhyahRQgzGUj","outputId":"eb31afbe-967e-468b-ece6-11d6bf00732e"},"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/200 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n","Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 200/200 [02:58<00:00,  1.12it/s]\n","100%|██████████| 200/200 [02:58<00:00,  1.12it/s]\n","100%|██████████| 200/200 [02:57<00:00,  1.13it/s]\n","100%|██████████| 200/200 [02:58<00:00,  1.12it/s]\n","100%|██████████| 200/200 [02:57<00:00,  1.13it/s]\n","100%|██████████| 200/200 [02:58<00:00,  1.12it/s]\n","100%|██████████| 200/200 [02:58<00:00,  1.12it/s]\n","100%|██████████| 200/200 [02:58<00:00,  1.12it/s]\n","100%|██████████| 200/200 [02:58<00:00,  1.12it/s]\n","100%|██████████| 200/200 [02:58<00:00,  1.12it/s]\n","100%|██████████| 400/400 [05:56<00:00,  1.12it/s]\n","100%|██████████| 400/400 [05:57<00:00,  1.12it/s]\n","100%|██████████| 400/400 [05:55<00:00,  1.13it/s]\n","100%|██████████| 400/400 [05:56<00:00,  1.12it/s]\n","100%|██████████| 400/400 [05:55<00:00,  1.12it/s]\n","100%|██████████| 400/400 [05:57<00:00,  1.12it/s]\n","100%|██████████| 400/400 [05:56<00:00,  1.12it/s]\n","100%|██████████| 400/400 [05:57<00:00,  1.12it/s]\n","100%|██████████| 400/400 [05:57<00:00,  1.12it/s]\n","100%|██████████| 400/400 [05:56<00:00,  1.12it/s]\n","100%|██████████| 200/200 [02:58<00:00,  1.12it/s]\n","100%|██████████| 200/200 [02:58<00:00,  1.12it/s]\n","100%|██████████| 200/200 [02:57<00:00,  1.12it/s]\n","100%|██████████| 200/200 [02:58<00:00,  1.12it/s]\n","100%|██████████| 200/200 [02:57<00:00,  1.13it/s]\n","100%|██████████| 200/200 [02:58<00:00,  1.12it/s]\n","100%|██████████| 200/200 [02:58<00:00,  1.12it/s]\n","100%|██████████| 200/200 [02:58<00:00,  1.12it/s]\n","100%|██████████| 200/200 [02:58<00:00,  1.12it/s]\n","100%|██████████| 200/200 [02:58<00:00,  1.12it/s]\n","100%|██████████| 400/400 [05:56<00:00,  1.12it/s]\n","100%|██████████| 400/400 [05:57<00:00,  1.12it/s]\n","100%|██████████| 400/400 [05:54<00:00,  1.13it/s]\n","100%|██████████| 400/400 [05:56<00:00,  1.12it/s]\n","100%|██████████| 400/400 [05:55<00:00,  1.13it/s]\n"," 29%|██▉       | 116/400 [01:43<04:12,  1.12it/s]"]}],"source":["device = torch.device('cuda')\n","\n","exp_dir = \"../out\"\n","G2 = models.get_model(\"stylegan3\", \"../pretrained/stylegan3/stylegan3-r-ffhqu-1024x1024.pkl\")\n","stylegan3_sample_generator = StyleGAN3SampleGenerator(G=G2, device=device)\n","\n","face_bisenet = models.get_model(\"face_bisenet\", \"../pretrained/face_bisenet/model.pth\")\n","face_segmentation = FaceSegmentation(face_bisenet=face_bisenet, device=device)\n","SG = \"sg3\" # activate this for sg3-r\n","\n","for latent_space in [\"S3\", \"S5\"]:\n","    for loss_function in [\"L2\"]:\n","        for mask_aggregation in [\n","            'average',\n","            'union',\n","            'intersection',\n","        ]:\n","\n","            for num_latent_dirs in [1, 2]:\n","                for part_name, face_parts in zip(\n","                        [\n","                            \"mouth\",\n","                            \"skin\",\n","                            \"eyes\",\n","                            \"nose\",\n","                            \"ears\",\n","                            \"background\",\n","                            \"eyebrows\",\n","                            \"hair\",\n","                            \"cloth\", \"eyeglass\"\n","\n","                        ],\n","                        [\n","                            [\"mouth\", \"u_lip\", \"l_lip\"],\n","                            [\"skin\"],\n","                            [\"l_eye\", \"r_eye\"],\n","                            [\"nose\"],\n","                            [\"l_ear\", \"r_ear\", \"earrings\"],\n","                            [\"background\"],\n","                            [\"l_brow\", \"r_brow\"],\n","                            [\"hair\", \"hat\"],\n","                            [\"hair\"],\n","                            [\"cloth\", \"neck\", \"necklace\"],\n","                            [\"eyeglass\"]\n","\n","                        ]\n","                ):\n","                    lr = 0.001\n","                    min_alpha_value = -1.0\n","                    max_alpha_value = 1.0\n","                    min_abs_alpha_value = 0.0\n","                    gamma_correlation = 5.0\n","                    onehot_temperature = 0.001\n","                    batch_size = 1\n","                    localization_layers = list(range(1, 15))\n","                    localization_layer_weights = None\n","                    log_dir = f'{exp_dir}/lelsd_stylegan3_ffhq/{latent_space}_{loss_function}_{mask_aggregation}/{num_latent_dirs}D/face_bisenet/{part_name}'\n","                    lelsd = LELSD(device=device,\n","                                  localization_layers=localization_layers,\n","                                  semantic_parts=face_parts,\n","                                  loss_function=loss_function,\n","                                  localization_layer_weights=localization_layer_weights,\n","                                  mode='foreground',\n","                                  mask_aggregation=mask_aggregation,\n","                                  n_layers=15,\n","                                  latent_dim=1024,\n","                                  num_latent_dirs=num_latent_dirs,\n","                                  learning_rate=lr,\n","                                  batch_size=batch_size,\n","                                  gamma_correlation=gamma_correlation,\n","                                  unit_norm=False,\n","                                  latent_space=latent_space,\n","                                  onehot_temperature=onehot_temperature,\n","                                  min_alpha_value=min_alpha_value,\n","                                  max_alpha_value=max_alpha_value,\n","                                  min_abs_alpha_value=min_abs_alpha_value,\n","                                  log_dir=log_dir, sg=SG\n","                                  )\n","\n","                    lelsd.fit(stylegan3_sample_generator, face_segmentation, num_batches=200 * num_latent_dirs,\n","                              num_lr_halvings=3,\n","                              pgbar=True, summary=True)\n","                    lelsd.save()"],"id":"XhyahRQgzGUj"},{"cell_type":"markdown","source":["### StyleGAN3-T FFHQ"],"metadata":{"id":"uVMbHOalXoFg"},"id":"uVMbHOalXoFg"},{"cell_type":"code","execution_count":null,"metadata":{"id":"gGXftvPM04L2"},"outputs":[],"source":["device = torch.device('cuda')\n","\n","exp_dir = \"../out\"\n","G2 = models.get_model(\"stylegan3\", \"../pretrained/stylegan3/stylegan3-t-ffhq-1024x1024.pkl\")\n","stylegan3_sample_generator = StyleGAN3SampleGenerator(G=G2, device=device)\n","\n","face_bisenet = models.get_model(\"face_bisenet\", \"../pretrained/face_bisenet/model.pth\")\n","face_segmentation = FaceSegmentation(face_bisenet=face_bisenet, device=device)\n","SG = \"sg3-t\"\n","\n","for latent_space in [\"S3\", \"S5\"]:\n","    for loss_function in [\"L2\"]:\n","        for mask_aggregation in [\n","            'average',\n","            'union',\n","            'intersection',\n","        ]:\n","\n","            for num_latent_dirs in [1, 2]:\n","                for part_name, face_parts in zip(\n","                        [\n","                            \"mouth\",\n","                            \"skin\",\n","                            \"eyes\",\n","                            \"nose\",\n","                            \"ears\",\n","                            \"background\",\n","                            \"eyebrows\",\n","                            \"hair\",\n","                            \"cloth\", \"eyeglass\"\n","\n","                        ],\n","                        [\n","                            [\"mouth\", \"u_lip\", \"l_lip\"],\n","                            [\"skin\"],\n","                            [\"l_eye\", \"r_eye\"],\n","                            [\"nose\"],\n","                            [\"l_ear\", \"r_ear\", \"earrings\"],\n","                            [\"background\"],\n","                            [\"l_brow\", \"r_brow\"],\n","                            [\"hair\", \"hat\"],\n","                            [\"hair\"],\n","                            [\"cloth\", \"neck\", \"necklace\"],\n","                            [\"eyeglass\"]\n","\n","                        ]\n","                ):\n","                    lr = 0.001\n","                    min_alpha_value = -1.0\n","                    max_alpha_value = 1.0\n","                    min_abs_alpha_value = 0.0\n","                    gamma_correlation = 5.0\n","                    onehot_temperature = 0.001\n","                    batch_size = 1\n","                    localization_layers = list(range(1, 15))\n","                    localization_layer_weights = None\n","                    log_dir = f'{exp_dir}/lelsd_stylegan3_ffhq/{latent_space}_{loss_function}_{mask_aggregation}/{num_latent_dirs}D/face_bisenet/{part_name}'\n","                    lelsd = LELSD(device=device,\n","                                  localization_layers=localization_layers,\n","                                  semantic_parts=face_parts,\n","                                  loss_function=loss_function,\n","                                  localization_layer_weights=localization_layer_weights,\n","                                  mode='foreground',\n","                                  mask_aggregation=mask_aggregation,\n","                                  n_layers=15,\n","                                  latent_dim=1024,\n","                                  num_latent_dirs=num_latent_dirs,\n","                                  learning_rate=lr,\n","                                  batch_size=batch_size,\n","                                  gamma_correlation=gamma_correlation,\n","                                  unit_norm=False,\n","                                  latent_space=latent_space,\n","                                  onehot_temperature=onehot_temperature,\n","                                  min_alpha_value=min_alpha_value,\n","                                  max_alpha_value=max_alpha_value,\n","                                  min_abs_alpha_value=min_abs_alpha_value,\n","                                  log_dir=log_dir, sg=SG\n","                                  )\n","\n","                    lelsd.fit(stylegan3_sample_generator, face_segmentation, num_batches=200 * num_latent_dirs,\n","                              num_lr_halvings=3,\n","                              pgbar=True, summary=True)\n","                    lelsd.save()\n"],"id":"gGXftvPM04L2"}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"train_lelsd_stylegan2.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":5}