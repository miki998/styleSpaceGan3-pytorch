{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"synB2RO2jr5T","executionInfo":{"status":"ok","timestamp":1654775445357,"user_tz":-120,"elapsed":15960,"user":{"displayName":"miki998 Chan","userId":"13004190056137233486"}},"outputId":"2173d427-86f4-4a48-854a-fdbd700abb25"},"id":"synB2RO2jr5T","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# !pip install boto3 botocore awscli --ignore-installed\n","# !pip install ninja\n","\n","# !pip install torch==1.9.0\n","# !pip install torchvision==0.10.0"],"metadata":{"id":"R1deiE4IX3BW","executionInfo":{"status":"ok","timestamp":1654775580464,"user_tz":-120,"elapsed":133843,"user":{"displayName":"miki998 Chan","userId":"13004190056137233486"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"25de1714-2fda-473a-a4c4-ae233c2f6b9d"},"id":"R1deiE4IX3BW","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting boto3\n","  Downloading boto3-1.24.5-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 4.8 MB/s \n","\u001b[?25hCollecting botocore\n","  Downloading botocore-1.27.5-py3-none-any.whl (8.9 MB)\n","\u001b[K     |████████████████████████████████| 8.9 MB 39.3 MB/s \n","\u001b[?25hCollecting awscli\n","  Downloading awscli-1.25.5-py3-none-any.whl (3.9 MB)\n","\u001b[K     |████████████████████████████████| 3.9 MB 42.6 MB/s \n","\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n","  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 8.9 MB/s \n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n","Collecting python-dateutil<3.0.0,>=2.1\n","  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n","\u001b[K     |████████████████████████████████| 247 kB 68.8 MB/s \n","\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 70.1 MB/s \n","\u001b[?25hCollecting six>=1.5\n","  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n","Collecting PyYAML<5.5,>=3.10\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 63.6 MB/s \n","\u001b[?25hCollecting colorama<0.4.5,>=0.2.5\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Collecting docutils<0.17,>=0.10\n","  Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n","\u001b[K     |████████████████████████████████| 548 kB 66.2 MB/s \n","\u001b[?25hCollecting rsa<4.8,>=3.1.2\n","  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n","Collecting pyasn1>=0.1.3\n","  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 6.7 MB/s \n","\u001b[?25hInstalling collected packages: six, urllib3, python-dateutil, jmespath, pyasn1, botocore, s3transfer, rsa, PyYAML, docutils, colorama, boto3, awscli\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.9 which is incompatible.\n","google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed PyYAML-5.4.1 awscli-1.25.5 boto3-1.24.5 botocore-1.27.5 colorama-0.4.4 docutils-0.17.1 jmespath-1.0.0 pyasn1-0.4.8 python-dateutil-2.8.2 rsa-4.8 s3transfer-0.6.0 six-1.16.0 urllib3-1.26.9\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["dateutil","six"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ninja\n","  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n","\u001b[K     |████████████████████████████████| 108 kB 5.0 MB/s \n","\u001b[?25hInstalling collected packages: ninja\n","Successfully installed ninja-1.10.2.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.9.0\n","  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[K     |████████████████████████████████| 831.4 MB 2.6 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0) (4.2.0)\n","Installing collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.11.0+cu113\n","    Uninstalling torch-1.11.0+cu113:\n","      Successfully uninstalled torch-1.11.0+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.9.0 which is incompatible.\n","torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.9.0 which is incompatible.\n","torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchvision==0.10.0\n","  Downloading torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n","\u001b[K     |████████████████████████████████| 22.1 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0) (7.1.2)\n","Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0) (1.9.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0) (1.21.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchvision==0.10.0) (4.2.0)\n","Installing collected packages: torchvision\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.12.0+cu113\n","    Uninstalling torchvision-0.12.0+cu113:\n","      Successfully uninstalled torchvision-0.12.0+cu113\n","Successfully installed torchvision-0.10.0\n"]}]},{"cell_type":"code","execution_count":null,"id":"b6b80a9e","metadata":{"id":"b6b80a9e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654775783525,"user_tz":-120,"elapsed":212,"user":{"displayName":"miki998 Chan","userId":"13004190056137233486"}},"outputId":"ddce3a5c-647c-4687-9f21-80fc0711b6d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'drive/MyDrive/LELSD/notebooks'\n","/content/drive/MyDrive/LELSD/notebooks\n"]}],"source":["%cd drive/My\\Drive/LELSD/notebooks\n","\n","import numpy as np \n","import matplotlib.pyplot as plt\n","import datetime\n","import os\n","\n","import torch\n","\n","import sys\n","\n","sys.path.append(\"../\")\n","import models\n","from lelsd import LELSD\n","\n","from utils.stylegan2_utils import StyleGAN2SampleGenerator\n","from utils.stylegan3_utils import StyleGAN3SampleGenerator\n","\n","import cv2\n","from tqdm import tqdm\n","\n","import pickle\n","from spaceUtils import *"]},{"cell_type":"code","source":["def load_pretrained_model(model_name, dataset_name):\n","    if model_name != \"biggan\":\n","        G = models.get_model(model_name,\n","                             f\"../pretrained/{model_name}/{model2available_dataset[model_name][dataset_name]}\")\n","    else:\n","        G = models.get_model(model_name, model2available_dataset[model_name][dataset_name])\n","    return G\n","\n","def get_batch_data(sample_generator, seed, model_name, dataset_name, bs=10):\n","    batch_data = sample_generator.generate_batch(seed, return_image=True, return_style=True, batch_size=bs)\n","    return batch_data"],"metadata":{"id":"FhUFGLQPxZik"},"id":"FhUFGLQPxZik","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"08db8e04","metadata":{"id":"08db8e04"},"outputs":[],"source":["model2available_dataset = {\n","    \"stylegan2\": {\n","        \"FFHQ\": \"ffhq.pkl\",\n","    },\n","    \"stylegan3\": {\n","        \"FFHQ\": \"stylegan3-r-ffhqu-1024x1024.pkl\",\n","    }\n","}"]},{"cell_type":"code","execution_count":null,"id":"1df57796","metadata":{"id":"1df57796"},"outputs":[],"source":["# GLOBALS\n","\n","# we fix seed sequence so to have all same generated images \n","seqSize = 100\n","seedSeq = np.arange(seqSize)\n","\n","savePath = '../logs/'\n","\n","model_name     = 'stylegan3' # modify to the correct stylegan model you wish to compute info for\n","dataset_name   = 'FFHQ'\n","truncation_psi = 0.7 #default"]},{"cell_type":"code","execution_count":null,"id":"a7f989bf","metadata":{"id":"a7f989bf"},"outputs":[],"source":["G      = load_pretrained_model(model_name, dataset_name)\n","device = torch.device('cuda')\n","if model_name == 'stylegan2':\n","    SG = StyleGAN2SampleGenerator(G=G, device=device, truncation_psi=truncation_psi)\n","elif model_name == 'stylegan3':\n","    SG = StyleGAN3SampleGenerator(G=G, device=device, truncation_psi=truncation_psi)"]},{"cell_type":"markdown","source":["### 1. Generate and save Style Channels and Image "],"metadata":{"id":"H-h6rBiz57qy"},"id":"H-h6rBiz57qy"},{"cell_type":"markdown","source":["#### StyleGan2 YS codes generating"],"metadata":{"id":"4IJeiD37bpfO"},"id":"4IJeiD37bpfO"},{"cell_type":"code","execution_count":null,"id":"6488bfaa","metadata":{"scrolled":true,"id":"6488bfaa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654728697644,"user_tz":-120,"elapsed":115363,"user":{"displayName":"miki998 Chan","userId":"13004190056137233486"}},"outputId":"a0757dd4-a2fc-4b03-b429-5b3319b7fc48"},"outputs":[{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n","Setting up PyTorch plugin \"upfirdn2d_plugin\"... "]},{"output_type":"stream","name":"stderr","text":["\r1it [01:47, 107.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Done.\n"]},{"output_type":"stream","name":"stderr","text":["100it [01:54,  1.15s/it]\n"]}],"source":["# # save and generate specific seed relate ys/rgbys vectors FOR STYLE GAN 2\n","# YS    = []\n","# RGBYS = []\n","# for idx, seed in tqdm(enumerate(seedSeq)):\n","#     data   = get_batch_data(SG, seed, model_name, dataset_name, bs=1)\n","#     ys     = data['ys']\n","#     rgb_ys = data['rgb_ys']\n","\n","#     YS.append(ys)\n","#     RGBYS.append(rgb_ys)\n","\n","# with open('{}/ysCodes.pkl'.format(savePath), 'wb') as f:\n","#     pickle.dump(YS, f)\n","\n","# with open('{}/rgbysCodes.pkl'.format(savePath), 'wb') as f:\n","#     pickle.dump(RGBYS, f)"]},{"cell_type":"markdown","source":["#### StyleGan3 YS codes generating"],"metadata":{"id":"xWtZhPYKbvJo"},"id":"xWtZhPYKbvJo"},{"cell_type":"code","source":["# # save and generate specific seed relate ys vectors FOR STYLE GAN 3\n","# YS    = []\n","# for idx, seed in tqdm(enumerate(seedSeq)):\n","#     data   = get_batch_data(SG, seed, model_name, dataset_name, bs=1)\n","#     ys     = data['ys']\n","\n","#     YS.append(ys)\n","\n","# with open('{}/ysCodesS3R.pkl'.format(savePath), 'wb') as f:\n","#     pickle.dump(YS, f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v3A6rztdnaG-","executionInfo":{"status":"ok","timestamp":1654728838259,"user_tz":-120,"elapsed":112378,"user":{"displayName":"miki998 Chan","userId":"13004190056137233486"}},"outputId":"be52e8cf-7b63-48fd-c2f5-ae7c67ce9d83"},"id":"v3A6rztdnaG-","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n"]},{"output_type":"stream","name":"stderr","text":["100it [01:51,  1.12s/it]\n"]}]},{"cell_type":"markdown","source":["### 2. Generate and save Gradient Map of generated image (one layer: default=4) "],"metadata":{"id":"iCjf1Z2950Sr"},"id":"iCjf1Z2950Sr"},{"cell_type":"markdown","source":["#### StyleGan2 Gradient Maps generating"],"metadata":{"id":"YSpkOI4gbSBC"},"id":"YSpkOI4gbSBC"},{"cell_type":"code","source":["# # load previously generated ys codes from STYLE GAN 2\n","# with open('{}/ysCodes.pkl'.format(savePath), 'rb') as f:\n","#     YS = pickle.load(f)\n","# with open('{}/rgbysCodes.pkl'.format(savePath), 'rb') as f:\n","#     RGBYS = pickle.load(f)"],"metadata":{"id":"2hjHF2UEa8UA"},"id":"2hjHF2UEa8UA","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Uncomment for STYLE GAN 2\n","# L = 4 # modify here which layer you wish to compute the channels jacobian of\n","\n","# for batch in range(0,10): # batches of 10 to compute because 100 takes too much space at once\n","#     GRADS = []\n","#     S,T   = batch * 10, (batch+1) * 10\n","#     for i in tqdm(range(S,T)):\n","#         # instantiating inputs of ys Latent Space\n","#         ys     = YS[i]\n","#         rgb_ys = RGBYS[i]\n","\n","#         # here we computed all jacobians for the specific generated image that you see below (ys,rgb_ys are specific to that image)\n","#         lfunc, inp   = func_generator(SG, ys, rgb_ys, layer=L) \n","#         grads        = jacobian(lfunc, inp)\n","#         GRADS.append(grads)\n","\n","#     with open('{}/gradMapsS2/gradMapsB{}L{}.pkl'.format(savePath,batch,L), 'wb') as f:\n","#         pickle.dump(GRADS, f)"],"metadata":{"id":"LfVZP7pAjSAI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650648304179,"user_tz":-120,"elapsed":1054042,"user":{"displayName":"miki998 Chan","userId":"13004190056137233486"}},"outputId":"6fda5b5f-3d23-4e03-9c13-f667d752d1e0"},"id":"LfVZP7pAjSAI","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [31:13<00:00, 187.30s/it]\n"]}]},{"cell_type":"markdown","source":["#### StyleGan3 Gradient Maps generating"],"metadata":{"id":"Mfi9BsAPb1gm"},"id":"Mfi9BsAPb1gm"},{"cell_type":"code","source":["# # load previously generated ys codes from STYLE GAN 3 (by default R)\n","with open('{}/ysCodesS3R.pkl'.format(savePath), 'rb') as f:\n","    YS = pickle.load(f)"],"metadata":{"id":"NB9wHnXqa_z1"},"id":"NB9wHnXqa_z1","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Uncomment for STYLE GAN 3\n","L = 4 # modify here which layer you wish to compute the channels jacobian of\n","\n","for batch in range(0,10): # batches of 10 to compute because 100 takes too much space at once\n","    GRADS = []\n","    S,T   = batch * 10, (batch+1) * 10\n","    for i in tqdm(range(S,T)):\n","        # instantiating inputs of ys Latent Space\n","        ys     = YS[i]\n","\n","        # here we computed all jacobians for the specific generated image that you see below (ys,rgb_ys are specific to that image)\n","        lfunc, inp   = func_generator2(SG, ys, layer=L) \n","        grads        = jacobian(lfunc, inp)\n","        GRADS.append(grads)\n","\n","    with open('{}/gradMapsS3R/gradMapsS3RB{}L{}.pkl'.format(savePath,batch,L), 'wb') as f:\n","        pickle.dump(GRADS, f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jgk6SoLqnJCr","outputId":"2cb01f0c-111b-4a64-a772-7641eef1db0f"},"id":"Jgk6SoLqnJCr","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [2:00:34<00:00, 723.45s/it]\n","100%|██████████| 10/10 [2:00:29<00:00, 722.93s/it]\n","100%|██████████| 10/10 [2:00:30<00:00, 723.00s/it]\n","100%|██████████| 10/10 [2:00:31<00:00, 723.15s/it]\n","100%|██████████| 10/10 [2:00:29<00:00, 722.97s/it]\n","100%|██████████| 10/10 [2:00:29<00:00, 722.97s/it]\n","100%|██████████| 10/10 [2:00:27<00:00, 722.78s/it]\n","100%|██████████| 10/10 [2:00:29<00:00, 722.94s/it]\n","100%|██████████| 10/10 [2:00:27<00:00, 722.75s/it]\n"," 50%|█████     | 5/10 [1:00:15<1:00:16, 723.27s/it]"]}]},{"cell_type":"markdown","source":["### 3. Semantic Masks Generating"],"metadata":{"id":"S8SuBOhtbBio"},"id":"S8SuBOhtbBio"},{"cell_type":"code","source":["from utils.segmentation_utils import FaceSegmentation\n","face_bisenet      = models.get_model(\"face_bisenet\", \"../pretrained/face_bisenet/model.pth\")\n","face_segmentation = FaceSegmentation(face_bisenet=face_bisenet, device=device)"],"metadata":{"id":"9cnHX0erXDO9","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["74e99bc436bc48a8b565f724cf1af5fe","f6aac622693349589207d01e13d744e6","1036ba4914f348d39b0aeab077d1f731","4c99451cd13544aab8a6ab3c518c532e","945ef66bd7f2419e9af71665d3f783cc","df8294aab88d476faef2197164d3880c","109dae6970eb4dd0905e4bdbf08a6ce8","feaa3048235a430faa3244f91568606b","c804a49bf9aa43348bf2f81047e38902","63e17ecf739549c08bf92b6cb1c75158","1f544733e7024b2fab46294e5c9f0b7b"]},"executionInfo":{"status":"ok","timestamp":1654775809761,"user_tz":-120,"elapsed":2796,"user":{"displayName":"miki998 Chan","userId":"13004190056137233486"}},"outputId":"c010e49c-a89c-467a-e5a8-e0e661705fea"},"id":"9cnHX0erXDO9","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/44.7M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74e99bc436bc48a8b565f724cf1af5fe"}},"metadata":{}}]},{"cell_type":"code","source":["indexMap = {0:0, 1:1, 2:2, 3:2, 4:3, 5:3, 6:4, 7:5, 8:5, 9:6, 10:7, 11:8, 12:8, 13:8, 14:9, 15:10, 16:11, 17:12, 18:13  }\n","indexMapping = lambda x: indexMap[x]"],"metadata":{"id":"iU91IjUAi-2M"},"id":"iU91IjUAi-2M","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Mask generating for StyleGAN 2"],"metadata":{"id":"0c4dwhKUlDQu"},"id":"0c4dwhKUlDQu"},{"cell_type":"code","source":["# load previously generated ys codes from STYLE GAN 2\n","with open('{}/ysCodes.pkl'.format(savePath), 'rb') as f:\n","    YS = pickle.load(f)\n","with open('{}/rgbysCodes.pkl'.format(savePath), 'rb') as f:\n","    RGBYS = pickle.load(f)\n","\n","MASKS = []\n","for k in tqdm(range(len(YS))):\n","    img  = SG.generate_batch_from_ys((YS[k], RGBYS[k]), return_image=True)['image'][0]  \n","    mask = face_segmentation.predict(img)[0,0].cpu()    \n","    # mask = face_segmentation.predict(img)[0,0].cpu().apply_(indexMapping)\n","    MASKS.append(mask)\n","\n","with open('{}/maskS2/maskS2.pkl'.format(savePath), 'wb') as f:\n","    pickle.dump(MASKS, f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z9qInedrkVv9","executionInfo":{"status":"ok","timestamp":1654775974449,"user_tz":-120,"elapsed":11742,"user":{"displayName":"miki998 Chan","userId":"13004190056137233486"}},"outputId":"14b25715-08eb-47fd-d112-6599247bea3f"},"id":"z9qInedrkVv9","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 100/100 [00:09<00:00, 10.42it/s]\n"]}]},{"cell_type":"markdown","source":["#### Mask generating for StyleGAN 3"],"metadata":{"id":"jVQUH8l6lIlH"},"id":"jVQUH8l6lIlH"},{"cell_type":"code","source":["# load previously generated ys codes from STYLE GAN 3 (by default R)\n","with open('{}/ysCodesS3R.pkl'.format(savePath), 'rb') as f:\n","    YS = pickle.load(f)\n","\n","MASKS = []\n","for k in tqdm(range(len(YS))):\n","    img  = SG.generate_batch_from_ys(YS[k], return_image=True)['image'][0]  \n","    mask = face_segmentation.predict(img)[0,0].cpu().apply_(indexMapping)\n","    MASKS.append(mask)\n","\n","with open('{}/maskS3R/maskS3Rmerged.pkl'.format(savePath), 'wb') as f:\n","    pickle.dump(MASKS, f)    "],"metadata":{"id":"j0Q0R5MEkUEE"},"id":"j0Q0R5MEkUEE","execution_count":null,"outputs":[]},{"cell_type":"code","source":[" "],"metadata":{"id":"y8zwrjt6ig_N"},"id":"y8zwrjt6ig_N","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"name":"generateInfos.ipynb","provenance":[],"collapsed_sections":["H-h6rBiz57qy","iCjf1Z2950Sr"]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"74e99bc436bc48a8b565f724cf1af5fe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f6aac622693349589207d01e13d744e6","IPY_MODEL_1036ba4914f348d39b0aeab077d1f731","IPY_MODEL_4c99451cd13544aab8a6ab3c518c532e"],"layout":"IPY_MODEL_945ef66bd7f2419e9af71665d3f783cc"}},"f6aac622693349589207d01e13d744e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df8294aab88d476faef2197164d3880c","placeholder":"​","style":"IPY_MODEL_109dae6970eb4dd0905e4bdbf08a6ce8","value":"100%"}},"1036ba4914f348d39b0aeab077d1f731":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_feaa3048235a430faa3244f91568606b","max":46827520,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c804a49bf9aa43348bf2f81047e38902","value":46827520}},"4c99451cd13544aab8a6ab3c518c532e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_63e17ecf739549c08bf92b6cb1c75158","placeholder":"​","style":"IPY_MODEL_1f544733e7024b2fab46294e5c9f0b7b","value":" 44.7M/44.7M [00:00&lt;00:00, 96.3MB/s]"}},"945ef66bd7f2419e9af71665d3f783cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df8294aab88d476faef2197164d3880c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"109dae6970eb4dd0905e4bdbf08a6ce8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"feaa3048235a430faa3244f91568606b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c804a49bf9aa43348bf2f81047e38902":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"63e17ecf739549c08bf92b6cb1c75158":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f544733e7024b2fab46294e5c9f0b7b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}